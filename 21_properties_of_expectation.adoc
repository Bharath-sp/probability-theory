= Properties of Expectation =
:doctype: book
:author: Bharath Kumar S P
:email: bharath030195@gmail.com
:stem: latexmath
:eqnums:
:toc:

== Properties ==

*Property 1:*

Suppose stem:[X = \mathbf{1}_A] is a simple random variable for any stem:[A \in \mathcal{F}], then stem:[\mathbb{E}[X\] = P(A)]. The probability of a set can be viewed as the expectation of the indicator of that set.

We know that,

[stem]
++++
\mathbf{1}_A(\omega) = \begin{cases}
        1, & \omega \in A,\\
        0, & \omega \in A^c.
    \end{cases}
++++

So we have stem:[X = 1 \cdot \mathbf{1}_A + 0 \cdot \mathbf{1}_{A^c}]. Then stem:[\mathbb{E}[X\] = 1 \cdot P(A) + 0 \cdot P(A^c) = P(A)].

*Property 2:*

If stem:[X(\omega) \geq 0] for all stem:[\omega \in \Omega], i.e., it is a non-negative random variable, then stem:[\mathbb{E}[X\] \geq 0].

*Property 3:*

If stem:[X(\omega) \geq 0] for all stem:[\omega \in \Omega], and stem:[P(\{X =0\})=1], then stem:[\mathbb{E}[X\] = 0].

image::.\images\expectation_prop_01.png[align='center', 400, 300]

stem:[X] maps stem:[\omega \in A] to 0. And it is given that stem:[P(A)=1].

[stem]
++++
\mathbb{E}[X]  = \sup \{\mathbb{E}[q] : q \in \mathcal{S}(X) \}
++++

Since stem:[\mathbb{E}[q\] ] is non-negative for all stem:[q \in \mathcal{S}(X)], we need to show that every stem:[\mathbb{E}[q\] ] is 0 so that the supremum will be 0. Take any stem:[q \in \mathcal{S}(X)],

[stem]
++++
\begin{align*}  
q & = 0 \cdot \mathbf{1}_A + a_1 \cdot \mathbf{1}_{A_1} + a_2 \cdot \mathbf{1}_{A_2} + \dots + a_n \cdot \mathbf{1}_{A_n} \\
\\
\mathbb{E}[q] & = 0 \cdot P(A) + a_1 \cdot P(A_1) + \dots + a_n \cdot P(A_n) = 0
\end{align*}
++++

Because each stem:[A_i] is a subset of stem:[A^c], and we know stem:[P(A^c)=0].

*Property 4:*

If stem:[X(\omega) \geq 0] for all stem:[\omega \in \Omega], and stem:[\mathbb{E}[X\] = 0], then stem:[P(\{X =0\})=1].

*Property 5:*

If stem:[A \in \mathcal{F}] such that stem:[P(A)=0], then for *any* random variable stem:[X], we have stem:[\int_A X \, dP = \mathbb{E}[X \cdot \mathbf{1}_A\]=0].

*Property 6:*

If stem:[A \in \mathcal{F}] such that stem:[P(A)=1], then for *any* random variable stem:[X], we have stem:[\int_A X \, dP = \mathbb{E}[X \cdot \mathbf{1}_A\]= \int_\Omega X \, dP = \mathbb{E}[X\] ].

*Property 7:*

Expectation is a linear operator. For any stem:[a,b \in \mathbb{R}] and any random variables stem:[X] and stem:[Y],

[stem]
++++
\mathbb{E}[aX+bY]  = a\,\mathbb{E}[X] + b \, \mathbb{E}[Y],
++++

provided all the expectations (both LHS and RHS) are well-defined, i.e., not of the form stem:[\infty - \infty].

== Discrete and Continuous RVs ==
Fix a probability space stem:[(\Omega, \mathcal{F}, P)]. Let stem:[X: \Omega \rightarrow \mathbb{R}] be a random variable with respect to stem:[\mathcal{F}].

If stem:[X] is a discrete random variable with PMF stem:[p_X], then

[stem]
++++
\mathbb{E}[X]  = \sum_x x \cdot p_X(x)
++++

In general, when we have a function of stem:[X],

[stem]
++++
\mathbb{E}[g(X)]  = \sum_x g(x) \cdot p_X(x)
++++

provided the RHS is well-defined, i.e., not of the form stem:[\infty - \infty]. 

If stem:[X] is a continuous random variable with PDF stem:[f_X], then

[stem]
++++
\mathbb{E}[X]  = \int_{-\infty}^{+ \infty} x \cdot f_X(x) \, dx
++++

In general,

[stem]
++++
\mathbb{E}[g(X)]  = \int_{-\infty}^{+ \infty} g(x) \cdot f_X(x) \, dx
++++


provided the RHS is well-defined, i.e., not of the form stem:[\infty - \infty].

IMPORTANT: Here stem:[\mathbb{E}[X\]] has the interpretation of the mean value of stem:[X]. On average, what values does stem:[X] take?

A general rule of thumb is to compute the expectation of stem:[X] always as:

[stem]
++++
\mathbb{E}[X] = \mathbb{E}[X_+] - \mathbb{E}[X\_],
++++

When both the terms are not stem:[+\infty] at the same time, only then we can define the expectation of stem:[X]. 

== Compute the Expectation ==
But how to compute stem:[\mathbb{E}[X_+\]] and stem:[ \mathbb{E}[X\_\]].

We know that stem:[g(X) = X_+ = \max \{X,0\}] is a function of stem:[X]. When stem:[X] is a discrete random variable,

[stem]
++++
\begin{align*}
\mathbb{E}[X_+] = \mathbb{E}[g(X)] =  \sum_x g(x) \cdot p_X(x) & = \sum_x \max\{x,0\} \cdot p_X(x) \\
& = \sum_{x \geq 0} x \cdot p_X(x)
\end{align*}
++++

When stem:[X] is a continuous random variable,

[stem]
++++
\begin{align*}
\mathbb{E}[X_+] = \mathbb{E}[g(X)] =  \int_{-\infty}^{+ \infty} g(x) \cdot f_X(x) \, dx & = \int_{-\infty}^{+ \infty} \max\{x,0\} \cdot f_X(x) \, dx \\
& = \int_0^{\infty} x \cdot f_X(x) \, dx 
\end{align*}
++++

stem:[\mathbb{E}[X_+\]] will always exists and it will be non-negative.

Similarly, We know that stem:[g(X) = X\_ = - \min \{X,0\}] is a function of stem:[X]. For positive values of stem:[x], stem:[\min\{x,0\} = 0]. When stem:[X] is a discrete random variable,

[stem]
++++
\begin{align*}
\mathbb{E}[X\_] = \mathbb{E}[g(X)] =  \sum_x g(x) \cdot p_X(x) & = \sum_x - \min\{x,0\} \cdot p_X(x) \\
& =  \sum_{x \leq 0} - x \cdot p_X(x)
\end{align*}
++++

When stem:[X] is a continuous random variable,

[stem]
++++
\begin{align*}
\mathbb{E}[X\_] = \mathbb{E}[g(X)] =  \int_{-\infty}^{+ \infty} g(x) \cdot f_X(x) \, dx & = \int_{-\infty}^{+ \infty} - \min\{x,0\} \cdot f_X(x) \, dx \\
& =  \int_{-\infty}^0 -x \cdot f_X(x) \, dx 
\end{align*}
++++

stem:[\mathbb{E}[X\_\]] will always exists and it will be non-negative.

== Examples ==

*Example 01:*

Let stem:[X] be a discrete random variable with the PMF

[stem]
++++
p_X(x) = \begin{cases}
        0.1, & x=1,\\
        0.2, & x=-2,\\
        0.2, & x=3,\\
        0.5, & x=-4,\\
        0, & \text{otherwise}.
    \end{cases}
++++

Compute stem:[\mathbb{E}[X\]].

[stem]
++++
\mathbb{E}[X_+] = \sum_{x \geq 0} x \cdot p_X(x) = 1 (0.1) + 3 (0.2)  \text{ which is } < +\infty
++++


[stem]
++++
\mathbb{E}[X\_] = \sum_{x \leq 0} - x \cdot p_X(x) = 2 (0.2) + 4 (0.5)  \text{ which is } < +\infty
++++

Hence, we can compute stem:[\mathbb{E}[X\] = \mathbb{E}[X_+\] - \mathbb{E}[X\_\]].

*Example 02:*

Let stem:[X] be a discrete random variable with the PMF

[stem]
++++
p_X(x) = \begin{cases}
        \frac{1}{x(x+1)}, & x \in \mathbb{N},\\
        0, & \text{otherwise}.
    \end{cases}
++++

Compute stem:[\mathbb{E}[X\]].

image::.\images\expectation_eg_02.png[align='center', 400, 600]

Since stem:[p_X(x) = 0 \, \, \forall x \notin \mathbb{N}], the expectation stem:[\mathbb{E}[X\_\]] has become 0. So the expectation of stem:[X] is defined and it is stem:[+\infty]. This means that the random variable takes arbitrarily large values as well with non-zero probability.

*Example 03:*

Let stem:[X] be a discrete random variable with the PMF

[stem]
++++
p_X(x) = \begin{cases}
        \frac{3}{\pi^2} \cdot \frac{1}{x^2} , & x \in \mathbb{Z} \backslash\{0\},\\
        0, & \text{otherwise}.
    \end{cases}
++++

Compute stem:[\mathbb{E}[X\]].

image::.\images\expectation_eg_03.png[align='center', 800, 600]

The issue with approach 1 is that, when we have both positive and negative terms in a summation, we cannot arbitrarily group terms. Grouping in a different way leads to different answers. For example,

image::.\images\group_terms_01.png[align='center', 500, 200]

To evaluate the summation, we have to evaluate the positive part first, and then evaluate the negative part. Then sum up both of them. So the first (top) one is the right solution for this summation.

*Example 04:*

Let stem:[X] be a continuous random variable with the PDF

[stem]
++++
f_X(x) = \frac{1}{\pi} \cdot \frac{1}{1+x^2}, \hspace{1cm} x \in \mathbb{R}.
++++

Compute stem:[\mathbb{E}[X\]]. This distribution is known as Cauchy distribution.

Approach 1:

[stem]
++++
\begin{align*}
\mathbb{E}[X] = \int_{-\infty}^{+ \infty} x \cdot f_X(x) \, dx & = c \int_{-\infty}^{+ \infty} \frac{x}{1+x^2} \, dx \\
& =  0 \text{ because } \frac{x}{1+x^2} \text{ is an odd function}.
\end{align*}
++++

This is incorrect. It turns out that stem:[\mathbb{E}[X_+\] = \infty] and stem:[\mathbb{E}[X\_\] = \infty]. Hence the expectation of stem:[X] is undefined.

== Expectation of Common RVs ==

[cols="1,1", width=50%]
|===
|stem:[X] |stem:[\mathbb{E}[X\]] - Mean of stem:[X]

|stem:[X \sim \text{Ber}(p)] |stem:[p]
|stem:[X \sim \text{Poisson}(\lambda)] |stem:[\lambda]
|stem:[X \sim \text{Unif}([a,b\])] |stem:[\frac{a+b}{2}]
|stem:[X \sim \text{Exp}(\mu)] |stem:[\frac{1}{\mu}]
|stem:[X \sim \mathcal{N}(\mu, \sigma^2)] |stem:[\mu]
|===


